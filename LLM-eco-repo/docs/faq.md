# FAQ（偏技术/方法论，不走营销腔）

作者：钟廷杰｜2026-01-16

> 这份 FAQ 主要回答：这个仓库的 demo 在做什么、没做什么、哪些地方容易误解。

---

## 1) 这是一个“LLM 项目”吗？

不完全是。

- 仓库主题是“文本信号 + 计量评估”，LLM 只是可能的升级方向。
- 当前 demo 用的是 TF‑IDF baseline（好处是透明、依赖少、可在 CI 跑通）。

如果你要把它升级成 LLM/RAG 版本，替换向量化与对齐模块就行，但评估口径（泄漏/EV/稳健性）这层反而更关键。

---

## 2) 为什么不用向量数据库 / embedding / 大模型？

两个原因：

1) 这个仓库的目标是“最小闭环 + 可复现”，不是追最强效果；
2) 很多问题不在模型能力，而在 **口径、对齐、评估与可审计性**。

把 baseline 做清楚，后面再换模型，反而更好对比变化来自哪里。

---

## 3) 中文上用 TF‑IDF 会不会很差？

会有局限。

- 中文没有天然空格，默认 tokenization 会失效。
- 这里用“字符 token + 空白 token”的混合 tokenizer，属于够用的折中（不引入分词依赖）。

更强的做法：引入分词、或直接用 embedding，并做人工抽样评估对齐质量。

---

## 4) 你怎么避免时间泄漏（look‑ahead bias）？

demo 里做了一个最常见、也最容易忽略的点：

- treated 的定义只用 pre‑2020 的收入均值，避免用 post 的信息去“定义处理组”。

真实项目里还需要：
- 明确 policy/event 的生效窗口
- 明确报告期与公告日的时间对齐
- 对滞后项/窗口做敏感性分析

---

## 5) 什么是 EV（Errors-in-Variables）校正？为什么要做？

当核心解释变量是“测量出来的 proxy”（文本指标经常就是），回归系数可能被系统性压小。

这里用一个简化版：
- 抽样一小部分做“人工标注”（在 demo 里用模拟生成）
- 用 `manual_label ~ proxy_raw` 估计衰减系数
- 再做 `proxy_corrected = proxy_raw / attenuation`

注意：如果 attenuation 过小，校正会放大噪声。代码里加了安全阈值并记录 warning。

---

## 6) DID 回归结果可信么？

就 demo 而言：它验证的是“流程能跑通”，不是结论本身。

想提升可信度，至少要做：
- 平行趋势检查/事件研究图
- 安慰剂检验（placebo）
- 更严谨的标准误处理（分组数足够时才 cluster）
- 口径变体/窗口变体的敏感性分析

---

## 7) 合成数据会不会误导别人？

合成数据的定位是：
- 让 pipeline、测试、CI 都能跑
- 让读者看懂字段与流程

它不用于支撑现实结论。把这个边界写清楚是基本的科研/工程素养。

---

## 8) 如果要把它当“准专业作品集”，你建议优先补什么？

按性价比排序：

1) 在 README 里写清楚：问题定义、数据边界、复现步骤、已知限制
2) 把测试与 CI 跑通（固定 Python 版本，确保一键可复现）
3) 加一页 case study（你做了什么、为什么这么做、踩坑点是什么）
4) 可选：把对齐质量做一个小的抽样评估（哪怕 30 条人工核验）
